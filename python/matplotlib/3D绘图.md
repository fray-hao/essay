最近在读《白话深度学习与TensorFlow》，决定撸一把 “神经网络深度学习” 知识。全栈之路上，必须占领人工智能这个技术高地。
读完前三章，至少掌握了基本的概念：如机器学习、深度学习、神经网络深度学习、梯度下降法、反向传播等基础概念，原理方面也非常通俗易懂。利用有限的学习时间，占领深度学习这个技术高地。
看到梯度下降法时，有一个Loss损失函数 ：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190402232022.png)

然后函数是显示在一个三维空间上的，特别想把这个函数的三维图片展示出来，于是有了写这篇小文章的初衷。

## 绘制三维散点图
```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# 简单Demo
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_zlabel('z')

X = [1, 1, 2, 2]
Y = [3, 4, 4, 3]
Z = [1, 2, 1, 1]


# 绘制散点图
ax.scatter(X, Y, Z)
plt.show()
```

![](https://raw.githubusercontent.com/fray-hao/images/master/20190402232212.png)
