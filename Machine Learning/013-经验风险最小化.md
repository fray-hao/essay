这节起，我们开始学习理论（learning theory），讲一些和机器学习有关的理论方面的内容。


本节包括了：
- 偏差/方差（Bias/variance）
- 经验风险最小化（Empirical Risk Minization，ERM）
- 联合界引理与Hoeffding不等式
- 一致收敛（Uniform Convergence）

## 1. 偏差-方差权衡（bias variance trade-off）
以我们的第一个学习算法——最小二乘法——为例。
![](https://raw.githubusercontent.com/fray-hao/images/master/20190312144657.png)
 上图左的情况，直线对数据的拟合为欠拟合（under-fitting），即没有很好的拟合所有的数据，有很大的泛化误差，这种情况对应于高偏差（high bias）。因为它不能很好的拟合出这组具有二次函数特征的数据。很高的偏差意味着一个事实：即使你有成千上万的无穷多的训练数据，算法仍然不能拟合出二次函数，或者说，数据的二次结构。所以说，这样的算法偏差很高

对于上图右的情况，如果用一个四次多项式函数拟合这组数据，会得到精确的通过每个数据点的曲线，但是这个算法有一个问题，我们称之为过拟合(over-fitting),或者也可以说这个算法的方差很高（high variance）。高方差意味着一个事实：算法拟合出了数据中的一些奇怪的规律，或者说一些怪异的属性。

## 2. 经验风险最小化（Experience Risk Minimization，ERM）
定义一个线性分类器：
$$
h_\theta(x) = g(\theta^Tx)
$$
其中：
$$
g(z) = 1{z\geq0}\qquad (y\in \{0,1\})
$$
这个模型和logistic回归比较像。可以将这个分类器看做是按某种概率分布选取0或1作为类标签。
像往常一样，比如说我们有m个训练样本：
$$
S=\begin{Bmatrix}
    x^{(i)},y^{(i)}
\end{Bmatrix},1\leq i\leq m
$$
其中，假设$ x^{(i)},y^{(i)}$是独立同分布的，并且都服从某种概率分布。
> 例如，将房屋销售作为分类问题看待，根据房屋的特征判断其是否在未来六个月内被卖掉，这个概率分布就是它们是否会卖掉的先验概率分布。
> 垃圾邮件分类也是一样的，是否为垃圾邮件是由同一个概率分布决定的。

为了理解偏差方差现象，将会使用这样一个简化的机器学习模型。逻辑回归模型通过最大化对数似然性拟合出参数，但是为了更为深入地理解机器学习算法，我要假设一个机器学习的简化版的模型。

定义训练误差：
$$
\hat{\epsilon}(h_\theta)=\hat{\epsilon}_s(h_\theta) = \frac{1}{m}\sum_{i=1}^m1\{h_\theta(x)\neq y^{(i)}\}
$$
>$\hat{\epsilon}_s(h_\theta)$表示误差依赖于某个训练样本集。

这个公式的含义为被错误分类的样本占总体样本的比例，后面的累加为错误样本数，除以总体样本m即为所占比例。这个被定义为训练误差（training error），也被称为风险

经验风险最小化的工作方式是，选择分类器函数的参数，使得分类器的训练误差（training error）最小：
$$
\hat{\theta} = \arg\min_\theta\hat{\epsilon}(h_\theta)
$$
对于 ERM 来说，因为它是非凸的，故而一般的算法无法优化它，因为它是 NP 的。但值得注意的是，logistic回归与 SVM都是这种方法的凸性近似。 
再看另外一种等价的ERM的定义，我们不是在选择最优分类器函数的参数，而是在选择最优的分类器函数。
我们定义假设类。将其定义成由所有假设（线性分类器）构成的集合：
$$
H=\begin{Bmatrix}
    h_\theta:\theta\in\mathbb{R}^{n+1}
\end{Bmatrix}
$$
这是一个假设模型集合，每改变参数时，就会选取一个假设模型，logistic回归可以从中选取一个假设作为结果。

其中，ℎ为分类模型，输出为 0,1。其训练误差的定义为：
$$
\hat{\epsilon}(h) =\frac{1}{m}\sum_{i=1}^m1\{h(x)\neq y^{(i)}\} 
$$
ERM被重新定义为：
$$
\hat{h} = \arg\min_{h\in H}\hat{\epsilon}(h)
$$

实际上，我们并不关心训练误差的大小，我们关心的是分类器对于未知样本的预测能力，也就是一般误差（generation error）：
$$
\epsilon(h) = P_{(x,y)\text\textasciitilde D}(h(x)\neq y)
$$

接下来的任务，是证明最优化ERM能带来较小的一般误差。首先，我们引入两个引理。 

## 3. 联合界引理与Hoeffding不等式
1. 联合界引理（Union Bound）

联合界引理，也叫布尔不等式。即并集的上界,描述的是至少一个事件发生的概率不大于单独事件(事件之间未必独立)发生的概率之和.

令$A_1,A_2,…,A_k$是k个事件，这k个事件可以相互独立也可以不相互独立，那么我们会得到:
$$
P(A_1\cup A_2\cup...\cup A_k)\leq P(A_1)+P(A_2)+...+P(A_k)
$$

该定理可以用文氏图来说明：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190313081533.png)

即各个事件并集的概率一定小于等于这些事件概率的和。
2. 霍夫丁不等式(Hoeffding's inequality)
令$z_1,z_2,…,z_m$为m个独立同分布(i.i.d)变量，它们都服从Bernoulli分布，即：
$$P(z_i=1)=\phi,P(z_i=0)=1-\phi$$

我们用这m个随机变量的平均值来估计$\phi$,得到：
$$
\hat{\phi} = \frac{1}{m}\sum_{i=1}^mz_i
$$
为这些随机变量的均值，给定$\gamma>0$,则霍夫丁不等式为：
$$
P(|\hat{\phi}-\phi|>\gamma)\leq 2\exp(-2\gamma^2m)
$$
表达的是对真实分布的估计值与真实分布之间的差值大于  $\gamma$的概率不会超过右边式子的上界
如下图所示，阴影部分的概率最多就是霍夫丁不等式右侧的值。所以这个不等式给出了估计伯努利随机变量均值时犯错误的概率的上界
![](https://raw.githubusercontent.com/fray-hao/images/master/20190313091038.png)
这因为个上界随着m的增加而指数下降。当样本数量m增大时，高斯函数会更为凸起，两边的概率密度会减小，这就意味着，随着样本数量m的增加，我们对参数的估计将越来越逼近真实值。 

## 4.训练误差与一般误差
接下来，我们回到经验风险最小化。以逻辑回归为例
令H为包含k个有限假设的假设类：
$$
H=\begin{Bmatrix}
    h_1,h_2,...,h_k
\end{Bmatrix}
$$
这k个函数都是输入到输出的映射函数。ERM要做的是对于给定的训练集合，它会从这k个函数中选择一个，使得训练误差最小的假设
$$
\hat{h} = \arg\min_{h_i\in H}\hat{\epsilon_s}(h_i)
$$
我们要证明ERM选择的假设$\hat{h}$的一般误差存在上界。
需要证明：
1. 训练误差是一个对一般误差的很好的近似
   $$\hat{\epsilon}\approx \epsilon$$
2. ERM选择的假设的一般误差存在上界
   $$ \text{show bound on }\epsilon(\hat{h })$$

首先证明第一项，从猜想类H中任意选取一个假设$h_j$:
$$
h_j\in H
$$
定义：
$$
Z_i = 1\{h_j(x^{(i)})\neq y^{(i)}\}
$$
由于$Z_i$只能取0或1，所以它是一个伯努利随机变量，那么$P(Z_i=1)$应该是什么呢？换句话说，对于给定的假设$h_j$,当我从分布D中抽样时，$h_j$是错误分类的概率是多少？根据定义，它应该等于$h_j$的一般误差：
$$
P(Z_i=1)=\epsilon(h_j)
$$

而训练误差的定义是m个$1(Z_i = 1)$之和，即为m个服从Bernoulli分布的随机变量之和:
$$
\hat{\epsilon}(h_j)=\frac{1}{m}\sum_{i=1}^mZ_i=\frac{1}{m}\sum_{i=1}^m1\{h_j(x^{(i)})\neq y^{(i)}\}
$$
而根据Hoeffding不等式引理，得到： 
$$
P(|\epsilon(h_j)-\hat{\epsilon}(h_j)|>\gamma)\leq 2\exp(-2\gamma^2m)
$$
这个结论证明了，对于给定的假设$h_j$,训练误差将会以很大的概率近似于一般误差。假设m很大，右边这项会很小，那么一般误差与训练误差相差很大的概率将很小。

我们最终想证明的是训练误差是一个对于一般误差的很好的估计。不仅仅是对于$h_j$,而是对于假设类H中的所有k个假设。
为了证明这个结论，我们定义一个随机事件$A_j$，这个事件$|\epsilon(h_j)-\hat{\epsilon}(h_j)|>\gamma$。上面的霍夫丁公式可以简写为：
$$
P(A_j)\leq 2\exp(-2\gamma^2m)
$$

现在，我要证明：对于整个假设类H，存在一些假设，一般误差取很大值的概率存在上界：
$$
\begin{aligned}
   & P(\exists h_j\in H,|\epsilon(h_j)-\hat{\epsilon}(h_j)|>\gamma)
    \\&=P(A_1\cup A_2,\cup...,\cup A_k)
    \\&\leq \sum_{i=1}^kP(A_i) \qquad \footnotesize\text{//根据联合界引理}
    \\&\leq \sum_{i=1}^m 2\exp(-2\gamma^2m)
    \\&=2ke^{-2\gamma^2m}
\end{aligned}
$$
两边同时减去1：
$$
\begin{aligned}
    &P(\nexists h_j\in H,|\epsilon(h_j)-\hat{\epsilon}(h_j)|>\gamma)
\\& = P(\forall h_j\in H,|\epsilon(h_j)-\hat{\epsilon}(h_j)|\leq\gamma)
\\&\geq 1- 2ke^{-2\gamma^2m}
\end{aligned}
$$

也就是说，在不小于$1- 2ke^{-2\gamma^2m}$的概率下，对于猜想类H中的所有假设h，其训练误差和一般误差之间的差距将会在$\gamma$以内。
这被称为一致收敛(uniform conversions)。一致收敛暗示了一个事实，当m很大时，所有的这些训练误差$\hat{\epsilon(h_j)}$将同时收敛到$\epsilon(h_j)$

## 5. 一致收敛

$$
\begin{aligned}
 P(\forall h_j\in H,|\epsilon(h_j)-\hat{\epsilon}(h_j)|\leq\gamma)\geq 1- 2ke^{-2\gamma^2m}
\end{aligned}
$$

上述形式实际就是一个概率的界。假设我固定训练集合，并且固定我的误差阈值$\gamma$,一致收敛成立的概率是多少？上述公式给出了答案，它给出的是某件事发生的概率

在一致收敛中，有三个参数：m,⁡γ,P。这三个参数是相互关联的，我们可以通过固定其中两个，来推出第三个。其中固定m,⁡γ来求P已经得出了。下面依次对另外两种参数关联进行说明，来得到一致收敛的另外两种等价形式。
 
 第一个，给定$\gamma$和$\delta$(概率)，需要多大的训练集合，才能符合$\gamma$和$\delta$要求的一致收敛界限.换句话说，给定$\gamma$和$\delta$，需要多少样本，可以保证在至少有1-$\delta$的概率，使得一般错误率在训练错误率的γ范围内？ 

 定义$\delta = 2ke^{(-2\gamma^2m)}$,那么：
 $$
 m\geq \frac{1}{2\gamma^2}\log\frac{2k}{\delta}
 $$
意思是，只要你的训练集合包含至少上述m这么多的样本，那么概率至少在$1-\delta$下，有$|\epsilon(h)-\hat{\epsilon}(h)|\leq \gamma$对H中的所有假设成立。
这个推论的意义为，一个算法或者模型要达到一个确定的性能时，需要的样本数目。也称为算法的样本复杂度。 
> log函数是增长速度最慢的函数之一，而m和log是正比例的，这意味着可以增加很多假设，而所需的训练样本数，却不会有太大的提高。
$$\forall k \qquad \log k \leq 30$$


最后的一种形式是：误差界（eroor bound），也就是给定m和$\Delta$不变:
$$
|\hat{\epsilon}(h)-\epsilon(h)|\leq \sqrt{\frac{1}{2m}\log\frac{2k}{\delta}}
$$
证明过程如下：
假设，所有的h都有一般误差与训练误差相乘小于等于$\gamma$

$$\forall h\in H ,|\epsilon(h)-\hat{\epsilon}(h)|\leq \gamma\tag{1}$$ 

定义$\hat{h}$为H中具有最小训练误差的假设:
$$
\hat{h}=\arg\min_{h\in H}\hat{\epsilon}(h)\tag{2}
$$
h*为H中具有最小一般误差的假设:
$$
h^* = \arg\min_{h\in H}\epsilon(h)\tag{3}
$$

我们可以推出： 
$$
\begin{aligned}
    \epsilon(h)&\leq \hat{\epsilon}(h)+\delta\qquad\qquad\footnotesize\text{by (1)}\\&\leq \hat{\epsilon}(\hat{h})+\delta \qquad\qquad\footnotesize\text{by (2)}
    \\& \leq \epsilon(h^*)+\gamma+\gamma\qquad\footnotesize\text{by (1)}
    \\&= \epsilon(h^*)+2\gamma  \qquad\qquad\footnotesize\text{(4)}
\end{aligned}
$$
> 其中，第一个不等号成立是一致收敛定理的应用；第二个不等号成立是$\hat{h}$的定义决定，其本身为训练误差最小的假设；第三个不等号成立仍然是一致收敛定理的应用。

将这些推论综合一下，我们得到一个定理： 
令|ℋ| = k,给定m和σ > 0，那么至少有1-σ的概率能够成立如下公式：
 $$
 \epsilon(\hat{h})\leq \min_{h\in H}\epsilon(h)+ 2\sqrt{\frac{1}{2m}\log\frac{2k}{\delta}}
 $$
> 最小训练误差的假设的一般误差小于等于最小的一般误差加上后面的式子
 
 如何证明呢？
  $$
 \epsilon(\hat{h})\leq \underbrace{\min_{h\in H}\epsilon(h)}_{\epsilon(h^*)} 2\underbrace{\sqrt{\frac{1}{2m}\log\frac{2k}{\delta}}}_{\gamma}
 $$
 根据(4)可以证明
 直观上，我们可以把第一项$\epsilon(h^*)$看成是选择假设的偏差，第二项$2\sqrt{\frac{1}{2m}\log\frac{2k}{\delta}}$看成选择假设的方差。
 当我们将H替换为更复杂的猜想类H'，即H是H'的子集时，第一项只会变的更小，即偏差变小；而由于k的增大，第二项会变的更大，即方差变大。从而得出上面的定理。

 具体的说， 比如说我有一个假设类H，可能仅包含线性函数的线性回归、或者仅有线性特征的逻辑回归。我考虑将这个H换成一个包含了更多特征的新的类H',例如二次函数。所以$H\subseteq H'$.当更换假设类为H'后，需要怎么权衡呢？
 当选择一个复杂的模型假设时， |ℋ| = k会变大，导致不等式后的第二项变大，意味着方差变大；但是第一项却会变小，因为使用一个更加大的模型集合ℋ意味着可供选择的假设变多了，在多的那部分中可能有比原来还要小的模型，这样偏差就会变小。这种现象通常称为偏差方差权衡（bias variance tradeoff）。
 这两个概念的示意图，如下：
 ![](https://raw.githubusercontent.com/fray-hao/images/master/20190318093608.png)
 > 当增加模型复杂度的时候，训练集合的拟合就越好，训练误差会越来越小。由于偏差方差权衡的存在， 一般误差会先下降，之后会再上升，左边部分表示的是恰拟合，也就是高偏差，右边部分表示数据过拟合，同时伴随着较高的方差。这就是为什么，如果你想要最小化一般误差的话，一般会选取中间的模型复杂度。

 下一讲，会讲些可以自动选取模型复杂度的算法，从而使一般误差尽可能地接近最小值。现在回到前面讲的定理。这个定理是一个错误界定理（error bound theorem），对于给定的$m,\delta$,至少在$1-\delta$的概率下，$\gamma$的边界是什么。
 最后要讲的是这个公里的一个推论。固定$\gamma,\delta$以及错误界，求解m。
![](https://raw.githubusercontent.com/fray-hao/images/master/20190318102330.png)
 
 http://www.cnblogs.com/madrabbit/p/7095575.html

 https://blog.csdn.net/weiyongle1996/article/details/77483691