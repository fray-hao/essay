## Jenson inequality
在介绍EM算法的一般形式之前，先介绍Jensen不等式，因为推导过程会用到。
Jenson inequality是这样的：
令f(x)为一个凸函数，且它的二阶导数大于等于0（f(x)''≥0）
令X为一个随机变量
那么：
$$
f(E[X])\leq E(f(x))
$$
> Let f(x) be a convex function(eg. f''(x)≥0)
> Let x be a random variable
> then, $$
f(EX)\leq E(f(x))
$$

这个不等式的含义如下图所示：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190403091006.png)

我们可以进一步推导出，如果f(x)''>0,即f(x)为一个严格的凸函数。那么：
$$
E[f(x)] = f(E[x])\Leftrightarrow x =E[x], \small\text{x 是常量的概率是1} 
$$

如果 f(x)'' ≤ 0, 则f(x)为凹函数，那么：
$$
f(EX)\geq E(f(x))
$$

## EM

有一些关于概率$P(x,z;\theta)$的模型，但是我们只能观察到x。我们有x和z的联合概率分布，我们的目标是参数$\theta$的对数似然性最大化：
$$
\begin{aligned}
L(\theta)&=\sum_{i=1}^m\log P(x^{(i)};\theta)
\\&= \sum_{i=1}^m\log \sum_{z^{(i)}}P(x^{(i)},z^{(i)};\theta)
\end{aligned}
$$

所以，EM算法是一个进行极大似然估计的过程

### 形式化过程
EM算法的过程大致如下：

1. 初始化$\theta^{(0)}$,调整$Q(z)$使得$J(Q,\theta^{(0)})$与$\theta^{(0)}$相等，然后求出$J(Q,\theta^{(0)})$使得到最大值的$\theta^{(1)}$
2. 固定$\theta^{(1)}$，调整$Q(z)$使得$J(Q,\theta^{(1)})$与$\theta^{(1)}$相等，然后求出$J(Q,\theta^{(1)})$使得到最大值的$\theta^{(2)}$
3. 如此循环，使得$l(\theta)$的值不断上升，直到k次循环后，求出了$l(\theta)$的最大值$l(\theta^{(k)})$

![](https://raw.githubusercontent.com/fray-hao/images/master/20190404092051.png)

![](https://raw.githubusercontent.com/fray-hao/images/master/20190404093722.png)
### 推导过程
在问题定义中我们知道:

$$
\begin{aligned}
\text{arg}\;\;\underset{\theta}{\text{max}}\;\;l(\theta)&=\text{arg}\;\;\underset{\theta}{\text{max}}\;\;\underset{i=1}{\overset{m}{\sum}}log\;p(x^{(i)};\theta)\\ &=\text{arg}\;\;\underset{\theta}{\text{max}}\;\;\underset{i=1}{\overset{m}{\sum}}log\underset{z}{\sum}p(x^{(i)},z^{(i)};\theta) 
\end{aligned}
$$

接下来我们正式开始EM算法的推导： 

假设每一个$z^{(i)}$的分布函数为$Q_i$。固有$\sum_{Z}Q_{i}(z)=1,Q_{i}(z)\ge0$。所以：
$$
\begin{aligned}
l(\theta)&=\underset{i}{\sum}log\underset{z^{(i)}}{\sum}p(x^{(i)},z^{(i)};\theta)\quad\quad\quad\quad &(1)
\\&=\underset{i}{\sum}log\underset{z^{(i)}}{\sum}Q_{i}(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}&(2)
\\ &\ge \underset{i}{\sum}\underset{z^{(i)}}{\sum}Q_{i}(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}&(3) 
\end{aligned}
$$
对于上述公式中的第（2）步到第（3）步的理解：
1. 首先由于数学期望公式Y=g(x),g(x)为连续函数
    $$
    E(Y)=E(g(x)) = \sum_{k=1}^\infty g(x_k)p_k
    $$

    $\underset{z^{(i)}}{\sum}Q_{i}(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}$可以看做g(x)函数为$\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}$,概率$p_i$为$Q_i(z^{(u)})$的数学期望，即：
    $$
    E(\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}) = \underset{z^{(i)}}{\sum}Q_{i}(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}
    $$
2. 有jenson不等式，且$f(x)=log\; x,f''(x)=-\frac{1}{x^{2}} <0$,所以：
   $$
   \begin{aligned}
 f(\underset{}{E}_{z^{(i)}\sim Q_{i}}[\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}])\ge \underset{}{E}_{z^{(i)}\sim Q_{i}}[f(\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})})]
 \end{aligned}
   $$
所以参数θ的对数似然性就有了一个下界，我们回想在EM算法的形式化过程中的不断推进得到的下界不断上升的过程，在这里我们也希望得到一个更加紧密的下界，也就是使等号成立的情况。 
根据Jensen不等式，所以有：
$$
\begin{aligned}\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})} =c \;\;\;(c为常数) \end{aligned}
$$
所以：
$$Qi(z(i))=c∗p(x(i),z(i);θ)(c为常数)$$
因为$\sum_{Z}Q_{i}(z)=1,Q_{i}(z)\ge0$,所以：
$$\begin{aligned}\sum_{Z}{Q_{i}(z^{(i)})} =\sum_{Z}c*{p(x^{(i)},z^{(i)};\theta)}=1 \;\;\;(c为常数) \end{aligned}$$
所以：
$$\begin{aligned}c=\frac{1}{\sum_{Z}{p(x^{(i)},z^{(i)};\theta)} }\;\;\;(c为常数) \end{aligned}$$
所以：
$$
\begin{aligned}Q_{i}(z^{(i)})&=\frac{p(x^{(i)},z^{(i)};\theta)}{\sum_{z}{p(x^{(i)},z;\theta)}}\\&=\frac{p(x^{(i)},z^{(i)};\theta)}{{p(x^{(i)};\theta)}}\\&=p(z^{(i)}|x^{(i)};\theta) \end{aligned}
$$
### 算法
EM算法主要有两个步骤，EM算法的具体内容如下：
Repeat until convergence{

1. (E-step) for each i, set 
   $$\begin{aligned}Q_{i}(z^{(i)}):=p(z^{(i)}|x^{(i)};\theta) \end{aligned}$$
2. (M-step) set 
    $$
    \begin{aligned}\theta:=\text{arg}\;\;\underset{\theta}{\text{max}}\;\;\underset{i}{\sum}\underset{z^{(i)}}{\sum}Q_{i}(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})} \end{aligned}
    $$
}

### 收敛性证明

我们可以定义一个优化目标 ：
$$
\begin{aligned}J(Q,\theta)=\underset{i}{\sum}\underset{z^{(i)}}{\sum}Q_{i}(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_{i}(z^{(i)})}\end{aligned}
$$
使用Jensen不等式，我们可以推导出： 
$$\begin{aligned}l(\theta)\geq J(Q,\theta)\end{aligned}$$

回顾前面所学的知识，EM 可以看作是函数 J 的坐标上升法，E步固定θ优化Q，M 步固定Q优化θ。 再利用相关知识便可以证明。
https://blog.csdn.net/danerer/article/details/80282612
https://blog.csdn.net/u012990623/article/details/42323661