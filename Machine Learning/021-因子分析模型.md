https://blog.csdn.net/stdcoutzyx/article/details/37559995

之所以要讲它，主要基于两个原因。
1. 它是一个非常有用的model。虽然它的应用并不如混合高斯模型或者混合贝叶斯模型那样广泛，但是还是很有用的。
2. 这个模型的推导过程用到的一些数学步骤是非常有用的。具体来说，对于因子分析，EM算法中的隐含随机变量是连续取值的。而因子分析模型的推导过程和之前看到的一些推导过程不太一样。

为了引出这个模型，我们需要将其和混合高斯模型做比较。

在介绍高斯模型的时候，我们用过这样的一个数据集合

![](https://raw.githubusercontent.com/fray-hao/images/master/20190415090909.png)

这个数据集的维度为2，样本量大约100.我们希望对这个无标记的训练样本用包含两个分布的混合高斯模型进行建模。

当样本m非常大的时候，使用混合高斯模型是可以的。一般情况下，m应该至少大于样本的维度n。这样就存在一个问题，如果你的数据维度n等于m或者远远大于m。这时该怎么做。对于高纬的数据如何建模？这种情况经常会遇到。

假设我们的数据$\{x^{(1)},x^{(2)},...,x^{(m)},\}$具有这样的性质，那么应该怎么对P(x)进行建模。

我们可以不考虑混合高斯模型，直接用简单的高斯模型进行建模。

例如，x服从高斯分布：
$$
x\sim \mathcal{N}(\mu,\varSigma),\quad\varSigma\in \mathbb{R}^{n\times n}
$$
如果通过极大似然估计求这些参数的话。所有样本的平均值：
$$
\mu =\frac{1}{m}\sum_{i=1}^m x^{(i)}
$$
协方差：
$$
\varSigma =\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T
$$
实际上，如果数据的维度远大于训练样本的数目（$n>> m$）,通过极大似然估计得到的矩阵是奇异矩阵（意味着不满秩，而且特征值为0）。这意味着矩阵$\varSigma$是不可逆的。

例如，n=m=2：

![](https://raw.githubusercontent.com/fray-hao/images/master/20190415120127.png)

拟合高斯模型如下：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190415120702.png)
通过极大似然估计得到的高斯分布对应的轮廓是一个无限细而且无限长的形状。

也可以通过另外一种方式发现这个问题。将$\varSigma$代入高斯密度函数公式中：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190415121445.png)

> 前面分母为0，后面矩阵不可解.这不是一个好的算法模型

那么给定维度大于样本数目的数据后，该如何对P(x)进行建模呢？


追本溯源，这个问题可以认为是数据信息缺乏的问题，即从训练数据中得不到模型所需要的全部信息。解决办法就是减小模型所需要的信息。本文提到的手段有两个：
- 不改变现有模型，但是加强模型的假设。下面提到的协方差矩阵限制就是这类方法。
- 降低模型的复杂度，提出一个需要更少信息（更少参数即是需要更少参数）的模型。因子分析模型就是此类。

可以将协方差矩阵$\varSigma$限制为对角矩阵:
$$
\varSigma = \begin{pmatrix}
    \sigma_1^2 &...&0
    \\\vdots  &\sigma_2^2&\vdots
    \\0&...&\sigma_n^2
\end{pmatrix}
$$
矩阵的极大似然结果：
$$
\sigma_j^2 = \frac{1}{m}\varSigma_i(x^{(i)}_j-\mu_j)^2
$$
用图来表示，这样的矩阵意味着高斯分布的轮廓的轴和坐标轴是平行的：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190419083535.png)

这样的做法是有效的，对于给定的两个训练样本是可以得到一个非奇异协方差矩阵的，但是这样做会抛弃所有数据中的相关性质。所以这并不是一个好的模型。

实际上，你可以添加更为严格的约束。例如，令：
$$
\varSigma =\sigma^2J = \begin{pmatrix}
    \sigma^2 &...&0
    \\\vdots  &\sigma^2&\vdots
    \\0&...&\sigma^2
\end{pmatrix}
$$
令所有对角元素都是相同的，这意味着你限制高斯密度函数的轮廓必须是圆形的。
![](https://raw.githubusercontent.com/fray-hao/images/master/20190419084503.png)

无论将矩阵约束为一般化对角矩阵还是常值对角矩阵化矩阵，它们都是很强的假设。如果有足够的数据的话，你也许希望你的模型能够体现出一些变量之间的关联性。因子分析模型要做的就是这个事情。

---

因子分析模型（factor analysis model） 是这样对数据进行建模的。

我们需要假设存在一个隐含的随机变量，我们将这个变量设为z，它应该服从均值为0，协方差矩阵为单位矩阵的高斯分布：
$$
z\sim \mathcal{N}(0,I),\quad\quad z\in \mathbb{R}^d\ (d<n)
$$
> d小于样本x的维度n

再假设训练样本x由隐含变量z生成，即：
$$
x = \mu +\lambda z + \varepsilon
$$
其中，$\varepsilon\sim\mathcal{N}(0,\Psi)$

上述公式等价于当z已知的时候，x的概率分布：
$$
x|z\sim \mathcal{N}(\mu+\lambda z,\Psi)
$$

这既是因子分析模型的定义，该模型有三个参数：
$$
\begin{aligned}
    &\mu \in \mathbb{R}^n
    \\& \lambda\in \mathbb{R}^{n\times d}
    \\& \Psi\in \mathbb{R}^{n\times n},\quad\Psi\text{是对角矩阵}
\end{aligned}
$$

让我们看一个具体的例子。假设z是一维向量，x是二维向量：
$$
z\in \mathbb{R}^1,x\in\mathbb{R}^2
$$

再假设：
$$
\begin{aligned}
    &\lambda = \begin{bmatrix}
    2\\1
\end{bmatrix}
\\& \Psi = \begin{bmatrix}
    1&0
    \\0&2
\end{bmatrix}
\\& \mu = \begin{bmatrix}
    0\\0
\end{bmatrix}
\end{aligned}
$$

首先，生成mge随机变量z，如果z服从高斯分布的话，对其进行一系列随机取样后，可能得到这样的结果：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190419103820.png)

然后，乘以$\lambda$,转化为二维：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190419104123.png)

第三步，使用$\mu$进行平移。这个例子中$\mu$值为0，也就是不需要平移。

之后，加入随机抖动。因为$\varepsilon$服从高斯分布，这意味着需要为每个x进行采样，也就是以每个点为中心创建一个与坐标轴平行的对应着$\varepsilon$的高斯分布，从这些高斯分布中可以获得一些样本：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190419105224.png)
从这些高斯分布中获得的样本构成了对x的取样

一种非正式的对于这些数据的直观理解：我们认为这些数据实际上是从某些低纬空间中生成的，所以这里的x是由一维的直线空间生成的，但是在生成之后，要加上一点随机噪声，所以我们得到了二维的点。

----

为了描述模型的拟合方法,我们需要将高斯分布写成一种不同的形式