https://blog.csdn.net/stdcoutzyx/article/details/37559995

之所以要讲它，主要基于两个原因。
1. 它是一个非常有用的model。虽然它的应用并不如混合高斯模型或者混合贝叶斯模型那样广泛，但是还是很有用的。
2. 这个模型的推导过程用到的一些数学步骤是非常有用的。具体来说，对于因子分析，EM算法中的隐含随机变量是连续取值的。而因子分析模型的推导过程和之前看到的一些推导过程不太一样。

为了引出这个模型，我们需要将其和混合高斯模型做比较。

在介绍高斯模型的时候，我们用过这样的一个数据集合

![](https://raw.githubusercontent.com/fray-hao/images/master/20190415090909.png)

这个数据集的维度为2，样本量大约100.我们希望对这个无标记的训练样本用包含两个分布的混合高斯模型进行建模。

当样本m非常大的时候，使用混合高斯模型是可以的。一般情况下，m应该至少大于样本的维度n。这样就存在一个问题，如果你的数据维度n等于m或者远远大于m。这时该怎么做。对于高纬的数据如何建模？这种情况经常会遇到。

假设我们的数据$\{x^{(1)},x^{(2)},...,x^{(m)},\}$具有这样的性质，那么应该怎么对P(x)进行建模。

我们可以不考虑混合高斯模型，直接用简单的高斯模型进行建模。

例如，x服从高斯分布：
$$
x\sim \mathcal{N}(\mu,\varSigma),\quad\varSigma\in \mathbb{R}^{n\times n}
$$
如果通过极大似然估计求这些参数的话。所有样本的平均值：
$$
\mu =\frac{1}{m}\sum_{i=1}^m x^{(i)}
$$
协方差：
$$
\varSigma =\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T
$$
实际上，如果数据的维度远大于训练样本的数目（$n>> m$）,通过极大似然估计得到的矩阵是奇异矩阵（意味着不满秩，而且特征值为0）。这意味着矩阵$\varSigma$是不可逆的。

例如，n=m=2：

![](https://raw.githubusercontent.com/fray-hao/images/master/20190415120127.png)

拟合高斯模型如下：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190415120702.png)
通过极大似然估计得到的高斯分布对应的轮廓是一个无限细而且无限长的形状。

也可以通过另外一种方式发现这个问题。将$\varSigma$代入高斯密度函数公式中：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190415121445.png)

> 前面分母为0，后面矩阵不可解.这不是一个好的算法模型

那么给定维度大于样本数目的数据后，该如何对P(x)进行建模呢？


追本溯源，这个问题可以认为是数据信息缺乏的问题，即从训练数据中得不到模型所需要的全部信息。解决办法就是减小模型所需要的信息。本文提到的手段有两个：
- 不改变现有模型，但是加强模型的假设。下面提到的协方差矩阵限制就是这类方法。
- 降低模型的复杂度，提出一个需要更少信息（更少参数即是需要更少参数）的模型。因子分析模型就是此类。

