## 1. 正则化

以线性回归为例，我们会选择参数，使得似然性最大化：
$$
\begin{aligned}
    \max_\theta \Pi_iP(y^{(i)}|x^{(i)};\theta)
\end{aligned}\tag{1}
$$
上述公式是频率学派（frequency procedure）的一个例子。这个公式之后的哲学观点是这样的：在数据背后，有一组参数$\theta$,用来生成x和y，这些$\theta$是真实的（不是随机变量，只是不知道值是什么），控制了房价y，但是，我们不知道$\theta$的值是什么，我们要做的是用一些方法来估计参数$\theta$的值。极大似然估计是一种估计$\theta$值的一种可能的方法。

除了统计学派外，还有一个学派就是贝叶斯学派（Bayesian school）。贝叶斯学派的观点认为：我们不知道$\theta$的值，所以我们为$\theta$的值赋予一个先验分布(prior).用先验分布来表示$\theta$取值的不确定性。

贝叶斯学派认为θ是一个服从某一分布的变量,即$\theta\text{\textasciitilde}p(\theta)$，其值是未知的。在这一假设中，我们需要确认先验分布Prior Distribution P(θ)从而表达我们对参数θ出现的“信任程度”。

例如，$\theta$的先验概率可能服从高斯分布，均值为0，协方差矩阵为$\tau^2I$:
$$
\theta \text{\textasciitilde}N(0,\tau^2I)
$$
给定训练集：
$$
S= \begin{Bmatrix}
    x^{(i)},y^{(i)};i=1,...,m
\end{Bmatrix}
$$
$p(\theta)$表示了，在没有见到任何数据的时候，我认为它最可能的形式。
我们会计算，给定了训练集合之后的后验概率.
> 根据贝叶斯公式，$p(\theta)$ 与右侧的公式成正比



$$
p(\theta|S)∝(\Pi_{i=1}^m p(y^{(i)}|x^{(i)},\theta))p(\theta)\tag{2}
$$

> 注意公式1与公式2中条件概率的区别。公式2中$p(y^{(i)}|x^{(i)},\theta))$中x与$\theta$之间用逗号分隔，表示$\theta$是随机变量。而公式1中$P(y^{(i)}|x^{(i)};\theta)$中x与$\theta$以分号隔开，表示$\theta$是一个具体的未知量。

当我们要对一个新的x进行预测时，我们会计算在参数θ的条件下预测结果的条件概率，公式为：
$$
p(y|x,S) = \int_\theta p(y|x,\theta)p(\theta|s)d\theta
$$
为了得到一个可信的预测结果，我们可以使用y|x的期望:
$$
E\begin{bmatrix}
    y|x,S 
\end{bmatrix}= \int_y yp(y|x,S) dy
$$

https://blog.csdn.net/stdcoutzyx/article/details/18500441

https://www.jianshu.com/p/7ed336956ea0

https://blog.csdn.net/knight_wzz/article/details/52942970