机器学习算法中有很多算法，那么在实际问题中应该怎样使用这些算法？当算法遇到瓶颈时该选择什么样的方向对算法进行改进？这篇文章既是解决这样的问题。这些建议针对已有的算法用到具体问题上，对发明新的算法用处不大。

本文聚集在三个主要内容：
- 调试ML算法时如何进行诊断（diagnostics for debugging learning algorithms）
- 误差分析与销蚀分析（error analysis and ablative analysis）
- 如何在一个ML问题上进行研究（how to get started on a machine learning problem）

在对具体的内容分析之前，先介绍一个很有用的建议，即避免过早优化（premature optimization）。

在我们进行项目开发或课题研究时，往往会遇到一些问题，在没有弄清楚问题之前，即没有明确的证据说明问题确实出在这里，我们往往想当然的对自己认为出问题的地方进行改进或优化，运气好时能把问题解决，运气不好则浪费了时间。

比如，在项目开发时，过早的优化不是瓶颈的代码段。例如，使用汇编语言来实现。虽然该代码段被优化得很快，但对系统的性能提高微乎其微，可以说是浪费了时间。而对于研究来说，过早的去做一些不能解决问题的事情浪费的时间可能会更多。因而，我们必须有一些能够判断问题所在的方法。这就引出了我们下面的内容。

## 1. 学习算法的调试问题

比如你想建立一个垃圾邮件识别系统。目前的研究现状如下：
- 经过仔细地**筛选**，在50000个特征（词）中选择了具有100个特征的很小的集合，来建立垃圾邮件识别系统
- 使用贝叶斯逻辑回归模型**算法**(BLR)
  $$
    \max_\theta\sum_{i=1}^m\log p(y^{(i)}|x^{(i)},\theta)-\lambda||\theta||^2
  $$
- 使用梯度下降算法实现，目前的**测试**误差率为20%

那么下一步应该做什么？

为了减少误差，改进算法。可能的解决方法如下：
- 提供跟多的训练样本
- 是否使用更少的特征
- 是否使用更多的特征
- 选取的特征是不是不够好，是否能找到更好的特征
- 梯度下降还没有完全收敛，可以多迭代几次
- 尝试其他的算法，例如牛顿方法。测试是否收敛性更好
- 调整贝叶斯逻辑回归模型中的$\lambda$
-  尝试用SVM算法，测试是否比逻辑回归算法更好

实际上可能的方法数以百计，我们只列出这8项。其中有些方法肯定有效， 如果一一尝试的话非常耗时。

面对这8种方法，如何选择改进的方向呢？只能靠运气吗？当然不是，如果我们能找到几种标准，排除上面大部分的方向，只保留1、2个，那么就可以节省很多时间。
### 1.1 方差/偏差分析
第一个标准就是判定问题是出在高方差还是高偏差上。一般来说，高方差(high variance)针对的是过拟合问题，即训练误差很小但泛化误差很大。而高偏差（high bias）针对的是模型本身不适合的问题，如特征数目过少等问题，表现既是训练误差和泛化误差都很大。示意图如下：

那么如何判断是高方差还是高偏差呢？

![](https://raw.githubusercontent.com/fray-hao/images/master/20190327093905.png)
由图1的高方差学习曲线可以看到，在高方差下，随着样本数的增加测试误差会呈下降趋势，而训练误差随着样本数的增加会单调上升，因为随着测试点的增加，它越来越难拟合出完美的曲线。**高方差的诊断方法**就是：在高方差下可以比较训练误差和测试误差，如果它们之间相差很大，那么可以通过增加样本数目使得模型的过拟合程度减少，从而提高性能。

由图2的高偏差学习曲线可以看到，在高偏差下，样本增加到一定程度后，测试误差就不变了，即使增加再多的样本数，误差程度也不会进一步缩小了；而训练误差会随着样本数的增加而递增。所以，在高偏差下，当你发现训练误差超过预期误差后，即使增加再多的样本，也不能把训练误差拉倒预期误差之下。

回到前面的修正措施列表，我们可以将前4条进行分类
- 提供跟多的训练样本 ： **可以修正高方差**
- 使用更少的特征：**可以修正高方差**
- 是否使用更多的特征： **可以修正高偏差**
- 找到更好的特征： **可以修正高偏差**

更多的样本使拟合变得平衡，可以解决高方差的问题；更少的特征也可以降低过拟合的程度，解决高方差问题。更多的特征和更好的特征可以增加模型的复杂度，提高模型在数据上的拟合程度，从而解决高偏差问题。

如果能够区别是高方差还是高偏差就可以排除掉上面四项措施中的2种，从而节省大量时间。


###1.2 收敛与目标函数是否正确的问题

考虑下面的例子，仍是针对垃圾邮件判断问题。
- 使用贝叶斯逻辑回归模型可以达到正常邮件（non spam）上2%的错误率，但是判断垃圾邮件上也有2%的错误率（也就是说2%的可能正常的邮件也被过滤了）。
- 使用svm和线性核算法可以达到判断正常邮件上10%的错误率，判断垃圾邮件上有0.1%的错误率

这个例子说明的是，你建立垃圾邮件判别系统时，你特别希望使用逻辑回归实现，因为它计算效率很高，或者需要随时进行学习，或者因为逻辑回归运行更简单、更快速。但是，它的运行效果并不好，将2%的邮件误判为垃圾邮件是不可接受的。

所以，应该怎么办？伴随着这个问题的是算法的收敛性。

你可能怀疑BLR没有收敛，可以再进行多次迭代。实际上，如果你考虑逻辑回归的优化目标。比如，逻辑回归是J(θ)的话，如果将这个函数作为迭代次数的函数，迭代次数与目标函数的趋势图如下：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190327122354.png)
但是这样的趋势图在通常情况下不能分辨出目标函数是否已收敛。因为在训练的后期目标函数的每步优化往往都只能提高一点点。所以相对于查看曲线的方法，我们需要更好的判断逻辑回归是否收敛的方法。

另外一个问题是BLR模型的优化目标函数是否找对？例如，在垃圾邮件识别的例子里，你可能会关心这样的一个加权准确率函数：
$$
a(\theta) = \frac{1}{m}\sum_{i=1}^m w^{(i)}1\begin{Bmatrix}
  h_\theta(x^{(i)})= y^{(i)}
\end{Bmatrix}
$$
$a(\theta)$是对所有预测正确样本的加权求和。非垃圾邮件的权值相对于垃圾邮件要高点。因为相对于垃圾文件，你更希望正确的预测非垃圾邮件。

第二种诊断方法可以帮助你判断，问题到底是出在：
- 算法的收敛
- 目标函数的选择上

假设svm比逻辑回归的效果更好，这就意味着svm的加权准确率要高于逻辑回归的加权准确率：
$$
a(\theta_{svm})>a(\theta_{BLR})
$$
> $\theta_{svm}$表示由svm算法生成的参数；$\theta_{BLR}$表示由贝叶斯逻辑回归生成的参数。

现在，我们可以通过判断在BLR的目标函数上，$\theta_{svm}$与$\theta_{BLR}$的表现，来判断到底发生了什么问题。
BLR尝试最优化的目标函数：
$$
J(\theta) = \sum_{i=1}^m\log p(y^{(i)}|x^{(i)},\theta)-\lambda ||\theta||^2
$$
可能发生两种情况：
$$
\begin{aligned}
  &a(\theta_{svm})>a(\theta_{BLR})
  \\&J(\theta_{svm})>J(\theta_{BLR})
\end{aligned}
$$
因为贝叶斯逻辑回归要将$J(\theta)$最大化，$J(\theta_{svm})>J(\theta_{BLR})$意味着目前由贝叶斯逻辑回归输出的参数无法使得$J(\theta)$最大化，因为svm生成的参数可以使$J(\theta)$取一个更大的值。所以，这告诉我们BLR算法的收敛程度没有svm高，造成了其在实际问题中表现差，这个时候就需要改进训练算法，使之收敛程度更高。
$$
\begin{aligned}
  &a(\theta_{svm})>a(\theta_{BLR})
  \\&J(\theta_{svm})<J(\theta_{BLR})
\end{aligned}
$$

$J(\theta_{svm})<J(\theta_{BLR})$意味着,在目标函数的最大化上，贝叶斯逻辑回归比svm做的更好。但是对于我们所关心的加权准确率。svm却获得了更好的结果，这意味着某些参数即使不能使目标函数J最大化，也能获得更好的加权准确率。最大化$J(\theta)$并不一定意味着最大化加权准确率。这告诉我们，也许$J(\theta)$是一个错误的优化目标函数，此时应该改进目标函数

回到我开头列出的后四项改进措施上：
- 梯度下降还没有完全收敛，可以多迭代几次。 **解决收敛程度问题，改进算法**
- 尝试其他的算法，例如牛顿方法。测试是否收敛性更好**解决收敛程度问题，改进算法**
- 调整贝叶斯逻辑回归模型中的$\lambda$ **改进目标函数**
-  尝试用SVM算法，测试是否比逻辑回归算法更好**改进目标函数** 

下面来看一个诊断实例。

Ng以他的某些学生正在做的一个自动驾驶直升机飞行的项目作为例子来分析如何找到问题所在。首先，对于一个能自动驾驶直升机的程序来说，要经过如下步骤：
1. 建立一个精确的模拟器。
2. 选择一个损失函数J
3. 使用强化学习算法（Reinforcement Learning，RL）来对损失函数进行优化，输出参数$\theta_{RL}$。之后，我们会用这些参数来进行直升机的控制。

直升机控制的效果很差，我们进行相反的假设。假设下面的条件都成立：
- 直升机的模拟器很精确
- 假设强化学习算法能够在模拟条件下正确地控制飞机。也就是强化学习算法能够使损失函数$J(\theta)$最小化，从而能正确地控制直升机
- 再假设$J(\theta)$最小化对应着正确飞行。

如果这些条件都成立，那么参数$\theta_{RL}$就可以精确地控制直升机了。但是事实上$\theta_{RL}$并不能很好的控制直升机。这意味着上面的假设中至少有一项不成立。如何找出问题所在呢？

我们用的诊断方法是这样的。
- 首先，判断算法是否在模拟器上可以正常驾驶。如果算法能在模拟器上正常驾驶，而在实际中不能，那么问题可能出现在模拟器上
- 此外，让真实的人在虚拟环境与真实环境中驾驶飞机，根据他的驾驶策略得到参数$\theta_{human}$。判断真实的人的参数损失与算法学到的参数的损失的差别，若$J(\theta_{RL})>J(\theta_{human})$，则需要改进算法，使算法更收敛。
- 如果$J(\theta_{human})$更大，这意味着真人控制的飞机的位置的平方误差更大，但是实际上，人类的飞行能力要比强化学习算法更好。如果这种问题出现，那么很明显，问题出在代价函数上。最小化的代价函数，并不意味着最好的飞行效果，所以应该尝试调整$J(\theta)$

以上的ML算法诊断在没有问题的时候可以可以使用，因为有利于搞清楚问题的本质，使你能更好的阐明问题与论点。

## 2. 误差分析（Error analysis）
在问题诊断中，我们的假设只有一个模型，但实际上，一个系统可能有多个部件组成。比如，一个基于人脸的性别识别系统，可能有如下几个部分组成。
按流程的先后顺序如下：
- 数据采集
- 数据预处理——背景消除
- 人脸识别
- 人脸器官识别——眼睛、鼻子、嘴
- 将器官识别结果作为属性输入到分类器模型如LR、SVM中
- 得到最后的分类结果

![](https://raw.githubusercontent.com/fray-hao/images/master/20190401085604.png)


https://blog.csdn.net/stdcoutzyx/article/details/18500441

误差分析是这样的：你使用的是一个很长很复杂的流水线，将许多机器学习组件组合起来。如果你能分析出误差是源于哪些组件，这将会很有帮助。

通常的误差分析过程是逐渐使用基准值（ground-truth）代替每个组件并观察准确率的变化。

例如，算法的正确率为85%，我们需要分析15%的误差在哪里。

首先，用手动编码的方法，而不是学习算法来去除背景，这时正确率提升到了85.1%；然后，在测试集合中告诉人脸的位置，这时准确率提升到了91%；以此类题，将每个组件的输出替换成基准值，最后形成如下的表格：
![](https://raw.githubusercontent.com/fray-hao/images/master/20190401091440.png)
> 需要注意: 上表中用基准值提交的部件是累积的，比如当眼睛识别用基准值代替时，其上的背景消除与人脸识别仍然用基准值替代。

经过这样的分析可知，对于整个系统，提高较多的部件是人脸识别和嘴识别。当然，器官识别中不同的基准值替代顺序可能会有不同的分析结果，所以要较为完备的进行比较，找到真正的瓶颈所在，避免过早优化问题。

## 3. 销蚀分析（ablative analysis）
销蚀分析是与误差分析相反的一种分析方式。误差分析尝试将现有的系统性能和完美的性能进行比较，而销蚀分析尝试解释当前系统性能和一些效果很差的底线（baselines）性能之间的差异。

比如，你建立了一个垃圾邮件分类器，并未逻辑回归算法加入了很多很好的特征。例如，你加入了拼写检查的特征，发送者主机的特征、邮件头的特征、邮件文本分析的特征、JavaScript解析的特征、嵌入图片的特征。你想总结一下这个特征，并且指出每种特征对于系统性能的改进有多少贡献。可能你想写一篇论文来说明这一点，以指出你的系统和之前系统的不同，你该怎么说明，并证明呢？

利用销蚀分析，我们可以这样做：在这个例子中，假设使用了简单的逻辑回归，没有加任何的改进得到了94%的性能提升。在销蚀分析中，我们不会每次添加一个组件，相反地，我们先将所有特征全部加入到系统中，然后每次会去除一个组件，来观察准确率的变化。将那些使性能没有下降或者下降很少的特征去除掉，找到真正有用的特征。
Component | Accuracy 
---------|----------
 Overall system | 99.9%
 spelling correction| 99.0% 
 Sender host features | 98.9%
 Email header features | 98.5%
 Email text parser features | 98%
 Javascript parser | 94.5%
 Features from messages | 94.0%

上表中，去除一个个特征后，算法的性能从99.9%降低到了94.0%，从中可以分析出那些特征会对系统性能造成大的影响。

当然，与误差分析一样，该方法可能对顺序敏感，所以需要多次试验才行。


## 4. 如何从头开始创建一个学习问题的算法研究

在学习问题的算法研究上，一般有两种做法：
- 仔细构建法（carefully design your system）
  对问题进行深入的分析，提取正确的特征，收集正确的数据集合，设计正确的算法结构然，后实现它。这样做的好处是，往往能得到具有伸缩性的算法，如果目标是对学习算法进行基础研究，这才是解决问题的基本方式。
- 创建-修改（build-and-fix）法
  这意味着我们需要先实现一些快速简陋的解决方案，之后利用误差分析来诊断，看看哪里有问题，之后再修改。这种方法的好处是可以快速的创建系统，这种方法非常适合产品创造。为对于工业界来说，胜出的往往不是最好的，而是第一个推出的，所以需要快速创建并部署系统。


> 设计诊断方法通常需要1/3到1/2的时间

